In recent years, the wealth of data available over the internet has given birth to new approaches to intellectual history - ones not reliant on curation by academia, but rather curation by the public (or at least those with access to the digital domain). As with all data, it can be gathered and quantified, offering the still relatively new landscape of digital humanities opportunities to build new metrics of measurement for concepts previously considered unquantifiable.

This thesis examines a singular dataset built with such a question in mind: can we measure the impact of an art movement, Dada, and can we use this data to understand it’s place in history better? Congruency in data and completeness is important, so we will be using one of the largest publicly available sources: Wikipedia.

Wikipedia is imbued with a set of biases: an over-representation of pop culture topics (Halvais and Lackoff, 2008), under-representation of women in biographies (Reagle and Rue, 2011) and issues of completeness (West and Williamson, 2009), to name a few. While the visualization does not broach this issue, this paper discusses it in more detail below.

The dataset is constructed using a crawler: it traverses the link structure of wikipedia articles to gather URLs and basic metadata such as location, time, and category, to build a interconnected web of topics related to Dada. Then, using proximity to Dada (the number of hyperlinks from Dada to the topic in question) and relative strength of the relationship (calculated by the number of pages also connected to Dada that are connected to the topic in question) a coefficient is constructed to provide a metric of the relationship.

To keep the crawler from drawing spurious connections, and the dataset from becoming over-inflated, the influence coefficient is capped and only allowed to gather articles within a certain threshold of strength. Similarly, causality is difficult to determine from link structure and meta-data alone: while some articles are easily catalogued by time, other articles are broad categories, and some basic NLP technology is used to inhibit the crawler from capturing overly-broad adjectives, also discussed below.

Last, the dataset is visualized using several variations on the force-directed graph, allowing for network analysis. Network analyses has a long history in mapping hidden structures (Lima, ) and more recently has been one of several interfaces for exploring link structures, including Wikipedia’s, like Chris Harrison’s ClusterBall, which maps wikipedia’s structure around broad topics, and other networks to look at the spread of ideas over time, such as NYT Labs Cascade tool. These novel interfaces to new forms of information come with strengths and biases worth further review.
